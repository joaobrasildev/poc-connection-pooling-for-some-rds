# ARCHITECTURE.md â€” Connection Pooling Proxy para SQL Server

> **PropÃ³sito deste documento:** fornecer ao agente de IA contexto completo do projeto
> em uma Ãºnica leitura, eliminando a necessidade de explorar arquivos um a um.
> Atualizar este doc a cada mudanÃ§a significativa.
>
> **Ãšltima atualizaÃ§Ã£o:** 2026-02-18 (Fase 3 concluÃ­da)

---

## 1. VisÃ£o Geral

POC de um **proxy de connection pooling** que fica entre aplicaÃ§Ãµes (.NET/Go/Python)
e instÃ¢ncias **SQL Server 2022 (RDS)**, controlando o nÃºmero de conexÃµes simultÃ¢neas
de forma centralizada via **Redis** e expondo mÃ©tricas via **Prometheus/Grafana**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Clients (sqlcmd, apps)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ TDS :1433
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    HAProxy L4    â”‚  leastconn
                        â”‚  (simula NLB)    â”‚  health: GET /health/live :8080
                        â””â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
                           â”‚     â”‚     â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ proxy-1  â”‚ â”‚proxy-2â”‚ â”‚ proxy-3   â”‚  Go binary
                 â”‚ :1433    â”‚ â”‚:1433  â”‚ â”‚ :1433     â”‚  TDS relay
                 â”‚ :8080    â”‚ â”‚:8080  â”‚ â”‚ :8080     â”‚  health
                 â”‚ :9090    â”‚ â”‚:9090  â”‚ â”‚ :9090     â”‚  metrics
                 â””â”€â”€â”¬â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”¬â”€â”€â”˜
                    â”‚  â”‚         â”‚            â”‚  â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”Œâ”€â”€â”€â”€â”˜            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚            â”‚    â”‚                 â”‚            â”‚
     â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
     â”‚ SQL Srv â”‚  â”‚    Redis    â”‚  â”‚  SQL Srv     â”‚  â”‚SQL Srvâ”‚
     â”‚ bucket-1â”‚  â”‚ coordinator â”‚  â”‚  bucket-2    â”‚  â”‚bkt-3  â”‚
     â”‚ :1433   â”‚  â”‚ :6379       â”‚  â”‚  :1433       â”‚  â”‚:1433  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Stack TecnolÃ³gica

| Componente     | Tecnologia                        | VersÃ£o      |
|----------------|-----------------------------------|-------------|
| Linguagem      | Go                                | 1.24.0      |
| SQL Server     | Microsoft SQL Server 2022 (Linux) | 16.0.4236   |
| Redis          | Redis                             | 7.4.x       |
| Load Balancer  | HAProxy                           | 3.1         |
| MÃ©tricas       | Prometheus + Grafana              | â€”           |
| Driver SQL     | `github.com/microsoft/go-mssqldb` | 1.9.6       |
| Driver Redis   | `github.com/redis/go-redis/v9`    | 9.18.0      |
| Containers     | Docker Compose                    | â€”           |
| Build          | Multi-stage: `golang:1.24-alpine` â†’ `alpine:3.19` |

---

## 3. Ãrvore de DiretÃ³rios

```
.
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ proxy/main.go              â† Entrypoint do proxy (176 loc)
â”‚   â”‚                                 Carrega config, inicia health/metrics/pool/coordinator/proxy
â”‚   â”‚                                 Graceful shutdown com SIGINT/SIGTERM
â”‚   â””â”€â”€ loadgen/main.go            â† Placeholder para load generator (14 loc)
â”‚
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.go              â† Carrega proxy.yaml + buckets.yaml, valida, aplica defaults (219 loc)
â”‚   â”‚
â”‚   â”œâ”€â”€ coordinator/               â† [FASE 3] CoordenaÃ§Ã£o distribuÃ­da via Redis
â”‚   â”‚   â”œâ”€â”€ lua/
â”‚   â”‚   â”‚   â”œâ”€â”€ acquire.lua        â† Script Lua atÃ´mico: GET count < max â†’ INCR + HINCRBY (33 loc)
â”‚   â”‚   â”‚   â””â”€â”€ release.lua        â† Script Lua atÃ´mico: DECR + HINCRBY -1 + PUBLISH (38 loc)
â”‚   â”‚   â”œâ”€â”€ redis.go               â† RedisCoordinator: Acquire/Release/Subscribe/Fallback (479 loc)
â”‚   â”‚   â”œâ”€â”€ heartbeat.go           â† Heartbeat periÃ³dico + cleanup de instÃ¢ncias mortas (196 loc)
â”‚   â”‚   â””â”€â”€ semaphore.go           â† SemÃ¡foro distribuÃ­do: Pub/Sub + polling fallback (135 loc)
â”‚   â”‚
â”‚   â”œâ”€â”€ health/
â”‚   â”‚   â””â”€â”€ health.go              â† Health checker: Redis PING + SQL SELECT 1 por bucket (265 loc)
â”‚   â”‚                                 HTTP: /health, /health/ready, /health/live
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ metrics.go             â† MÃ©tricas Prometheus prÃ©-registradas com promauto (92 loc)
â”‚   â”‚
â”‚   â”œâ”€â”€ pool/                      â† [FASE 1] Connection pool local por bucket
â”‚   â”‚   â”œâ”€â”€ connection.go          â† PooledConn: wrapper sobre *sql.DB com state/pin/metadata (175 loc)
â”‚   â”‚   â”œâ”€â”€ health.go              â† Health check: PingContext nas idle connections (61 loc)
â”‚   â”‚   â”œâ”€â”€ manager.go             â† Manager: mapa de BucketPool, Acquire/Release/Discard (134 loc)
â”‚   â”‚   â””â”€â”€ pool.go                â† BucketPool: LIFO idle stack, wait queue, eviction, min_idle (443 loc)
â”‚   â”‚
â”‚   â”œâ”€â”€ proxy/                     â† [FASE 2] TDS proxy transparente
â”‚   â”‚   â”œâ”€â”€ handler.go             â† Session: Pre-Login relay â†’ coordinator.Acquire â†’ TCP relay (293 loc)
â”‚   â”‚   â”œâ”€â”€ listener.go            â† Server: TCP listener, accept loop, graceful shutdown (158 loc)
â”‚   â”‚   â””â”€â”€ router.go              â† Router: Login7â†’bucket por database/serverName/username (136 loc)
â”‚   â”‚
â”‚   â”œâ”€â”€ queue/                     â† [FASE 3] Fila distribuÃ­da
â”‚   â”‚   â””â”€â”€ distributed.go         â† DistributedQueue: TryAcquire (fast) â†’ Wait (slow) (116 loc)
â”‚   â”‚
â”‚   â””â”€â”€ tds/                       â† Parser mÃ­nimo do protocolo TDS (MS-TDS spec)
â”‚       â”œâ”€â”€ packet.go              â† Header 8-byte, ReadPacket, ReadMessage, BuildPackets (266 loc)
â”‚       â”œâ”€â”€ prelogin.go            â† Parse/Marshal Pre-Login, encryption options (209 loc)
â”‚       â”œâ”€â”€ login7.go              â† Parse Login7: user, database, server, app (173 loc)
â”‚       â”œâ”€â”€ pinning.go             â† DetecÃ§Ã£o de pinning: BEGIN TRAN, sp_prepare, ENVCHANGE (374 loc)
â”‚       â”œâ”€â”€ relay.go               â† Relay bidirecional TDS, ForwardLogin7, DrainResponse (173 loc)
â”‚       â””â”€â”€ error.go               â† Construtor de TDS ERROR token para enviar ao client (179 loc)
â”‚
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ bucket/
â”‚       â””â”€â”€ bucket.go              â† Struct Bucket com DSN(), Addr() (49 loc)
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ proxy.yaml                 â† Config do proxy: listen, redis, fallback
â”‚   â””â”€â”€ buckets.yaml               â† 3 buckets: bucket-001/002/003, max_connections=50
â”‚
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ docker-compose.yml         â† 11 containers: 3 SQL Server, 3 proxy, Redis, HAProxy, Prometheus, Grafana, init-db
â”‚   â””â”€â”€ haproxy/
â”‚       â””â”€â”€ haproxy.cfg            â† L4 TCP leastconn, health check HTTP :8080
â”‚
â”œâ”€â”€ grafana/                       â† Dashboards e datasources provisionados
â”œâ”€â”€ prometheus/
â”‚   â””â”€â”€ prometheus.yml             â† Scrape targets: proxy-1/2/3 :9090
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init-databases.sql         â† CREATE DATABASE tenant_db
â”‚   â”œâ”€â”€ seed-data.sql              â† Tabelas e dados de teste
â”‚   â”œâ”€â”€ wait-for-sql.sh            â† Aguarda SQL Server ficar pronto
â”‚   â””â”€â”€ run-loadtest.sh            â† Script de teste de carga
â”‚
â”œâ”€â”€ postman/                       â† Collection Postman para testes manuais
â”œâ”€â”€ Dockerfile                     â† Multi-stage build do proxy Go
â”œâ”€â”€ go.mod / go.sum                â† DependÃªncias Go
â”œâ”€â”€ README.md
â”œâ”€â”€ 01-ENTENDIMENTO-TECNICO.md     â† Documento de entendimento do problema
â””â”€â”€ 02-PLANO-DE-EXECUCAO.md        â† Plano de execuÃ§Ã£o com 8 fases
```

**Total:** ~4.515 linhas de Go em 23 arquivos.

---

## 4. Grafo de DependÃªncia entre Pacotes

```
cmd/proxy/main.go
  â”œâ”€â”€ internal/config           â† carrega YAML
  â”œâ”€â”€ internal/health           â† checker HTTP
  â”œâ”€â”€ internal/metrics          â† Prometheus registry
  â”œâ”€â”€ internal/pool             â† pool manager
  â”œâ”€â”€ internal/coordinator      â† Redis coordinator + heartbeat
  â””â”€â”€ internal/proxy            â† TDS proxy server
        â”œâ”€â”€ internal/config
        â”œâ”€â”€ internal/coordinator  â† coordinator.Acquire/Release por sessÃ£o
        â”œâ”€â”€ internal/metrics
        â”œâ”€â”€ internal/pool
        â”œâ”€â”€ internal/tds          â† packet parsing, pre-login, login7, relay
        â””â”€â”€ pkg/bucket

internal/coordinator
  â”œâ”€â”€ internal/config
  â”œâ”€â”€ internal/metrics
  â””â”€â”€ github.com/redis/go-redis/v9

internal/pool
  â”œâ”€â”€ internal/metrics
  â”œâ”€â”€ pkg/bucket
  â””â”€â”€ github.com/microsoft/go-mssqldb

internal/queue
  â”œâ”€â”€ internal/coordinator
  â””â”€â”€ internal/metrics

internal/tds
  â””â”€â”€ (nenhuma dependÃªncia interna)

pkg/bucket
  â””â”€â”€ (nenhuma dependÃªncia)
```

**Regra:** `pkg/` Ã© importÃ¡vel por qualquer pacote. `internal/` respeita visibilidade Go.
`tds` e `bucket` nÃ£o dependem de nada interno (folhas do grafo).

---

## 5. Fluxo de uma RequisiÃ§Ã£o SQL (End-to-End)

```
Client                HAProxy           Proxy (Go)              Redis           SQL Server
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”œâ”€ TDS PRELOGIN â”€â”€â”€â”€â”€â”€â–ºâ”‚                   â”‚                    â”‚                  â”‚
  â”‚                      â”œâ”€ TCP leastconn â”€â”€â–ºâ”‚                    â”‚                  â”‚
  â”‚                      â”‚                   â”œâ”€ parse PreLogin    â”‚                  â”‚
  â”‚                      â”‚                   â”œâ”€ pickBucket()      â”‚                  â”‚
  â”‚                      â”‚                   â”‚  (bucket-001)      â”‚                  â”‚
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”‚                      â”‚                   â”œâ”€ coordinator       â”‚                  â”‚
  â”‚                      â”‚                   â”‚  .Acquire(bucket)â”€â”€â–ºâ”‚ EVALSHA acquire  â”‚
  â”‚                      â”‚                   â”‚                    â”œâ”€ INCR count      â”‚
  â”‚                      â”‚                   â”‚â—„â”€â”€â”€â”€ slot ok â”€â”€â”€â”€â”€â”€â”¤  HINCRBY inst    â”‚
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”‚                      â”‚                   â”œâ”€ net.Dial â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                      â”‚                   â”œâ”€ forward PreLogin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                      â”‚                   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PreLogin Response â”€â”€â”€â”¤
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PreLogin Response â”€â”€â”€â”€â”€â”¤                    â”‚                  â”‚
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”‚â•â•â•â•â•â•â•â•â•â•â• TLS Handshake (transparente via io.Copy) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
  â”‚â•â•â•â•â•â•â•â•â•â•â• Login7 (encrypted, relayed transparently) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
  â”‚â•â•â•â•â•â•â•â•â•â•â• Login Response (encrypted, relayed) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”‚â”€â”€ SQL_BATCH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”œâ”€â”€ io.Copy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ REPLY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â—„â”€â”€ io.Copy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                      â”‚                   â”‚                    â”‚                  â”‚
  â”‚â”€â”€ TCP FIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                    â”‚                  â”‚
  â”‚                      â”‚                   â”œâ”€ cleanup()         â”‚                  â”‚
  â”‚                      â”‚                   â”œâ”€ coordinator       â”‚                  â”‚
  â”‚                      â”‚                   â”‚  .Release(bucket)â”€â”€â–ºâ”‚ EVALSHA release  â”‚
  â”‚                      â”‚                   â”‚                    â”œâ”€ DECR count      â”‚
  â”‚                      â”‚                   â”‚                    â”œâ”€ PUBLISH notify  â”‚
  â”‚                      â”‚                   â”œâ”€ close backend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ã—â”€â”€â”¤
```

### Detalhe importante sobre o fluxo atual

O proxy opera em modo **relay TCP transparente** apÃ³s o Pre-Login:
- **NÃƒO** faz parsing TDS durante TLS (tudo opaco via `io.Copy`)
- **NÃƒO** faz routing por Login7 (o bucket Ã© escolhido antes, no Pre-Login)
- **NÃƒO** usa o pool de conexÃµes `*sql.DB` para o trÃ¡fego TDS (usa `net.Dial` direto)
- O pool `*sql.DB` existe para health checks e operaÃ§Ãµes internas (`sp_reset_connection`)
- O Router (Login7-based) estÃ¡ implementado mas **nÃ£o Ã© usado** no fluxo atual
- A detecÃ§Ã£o de pinning (`tds/pinning.go`) estÃ¡ implementada mas **nÃ£o Ã© ativada** durante TCP relay

---

## 6. Componentes Principais â€” Resumo de Responsabilidades

### 6.1 `cmd/proxy/main.go`
**Orquestrador de startup/shutdown.** SequÃªncia:
1. `config.Load()` â†’ proxy.yaml + buckets.yaml
2. MÃ©tricas HTTP `:9090/metrics`
3. Health checker HTTP `:8080/health`
4. `pool.NewManager()` â†’ 3 BucketPools (5 idle cada)
5. `coordinator.NewRedisCoordinator()` â†’ Redis connect, Lua scripts, instance registration
6. `coordinator.NewHeartbeat().Start()` â†’ heartbeat periÃ³dico
7. `proxy.NewServer().Start()` â†’ TCP listener `:1433`
8. Aguarda SIGINT/SIGTERM â†’ shutdown reverso

### 6.2 `internal/proxy` â€” TDS Proxy
- **Server** (`listener.go`): TCP accept loop, spawna `Session` por conexÃ£o
- **Session** (`handler.go`): Lifecycle completo de uma sessÃ£o TDS
  - LÃª Pre-Login â†’ escolhe bucket â†’ `coordinator.Acquire` â†’ `net.Dial` backend
  - Forward Pre-Login â†’ relay TCP bidirecional â†’ cleanup + `coordinator.Release`
- **Router** (`router.go`): Resolve Login7 â†’ bucket (por server name / database / username)
  - *Implementado mas nÃ£o ativado no fluxo atual (bucket escolhido antes do Login7)*

### 6.3 `internal/coordinator` â€” CoordenaÃ§Ã£o DistribuÃ­da
- **RedisCoordinator** (`redis.go`):
  - `Acquire(ctx, bucketID)` â†’ EvalSha acquire.lua â†’ fallback local se Redis falhar
  - `Release(ctx, bucketID)` â†’ EvalSha release.lua â†’ PUBLISH para Pub/Sub
  - `Subscribe(ctx, bucketID)` â†’ canal de notificaÃ§Ã£o de releases
  - Fallback mode: `enterFallback()` / `ExitFallback()` com reconciliaÃ§Ã£o
- **Heartbeat** (`heartbeat.go`):
  - Envia `SET key TTL` a cada 10s
  - A cada 30s: detecta instÃ¢ncias mortas (sem heartbeat) e limpa seus contadores
- **Semaphore** (`semaphore.go`):
  - `Wait(ctx, bucketID, timeout)` â†’ Pub/Sub + polling para esperar slot
  - `TryAcquire(ctx, bucketID)` â†’ tentativa nÃ£o-bloqueante

### 6.4 `internal/pool` â€” Connection Pool Local
- **Manager** (`manager.go`): Mapa `bucketID â†’ BucketPool`, Acquire/Release/Discard
- **BucketPool** (`pool.go`):
  - Idle stack LIFO, wait queue (channel-based), `sp_reset_connection` no release
  - Maintenance loop (30s): evict stale, ensure min_idle
- **PooledConn** (`connection.go`): Wrapper sobre `*sql.DB` com state, pin, use count
- **HealthCheck** (`health.go`): `PingContext` em idle connections

### 6.5 `internal/tds` â€” Parser TDS MÃ­nimo
- **packet.go**: Header 8-byte, ReadPacket/ReadMessage/BuildPackets/WritePackets
- **prelogin.go**: Parse/Marshal Pre-Login, encryption flags
- **login7.go**: Parse Login7 (offset/length pairs, UTF-16 LE)
- **pinning.go**: Detecta BEGIN TRAN, sp_prepare, BULK_LOAD, ENVCHANGE tokens
- **relay.go**: Relay bidirecional, RelayMessage, ForwardLogin7, DrainResponse
- **error.go**: ConstrÃ³i TDS ERROR token (50001 pool exhausted, 50002 routing, 50003 backend)

### 6.6 `internal/queue` â€” Fila DistribuÃ­da
- **DistributedQueue** (`distributed.go`): Wrapper que combina Semaphore + Coordinator
  - Fast path: `TryAcquire` â†’ slow path: `semaphore.Wait` com timeout

---

## 7. Redis â€” Chaves e PadrÃµes

| Chave                               | Tipo      | TTL  | DescriÃ§Ã£o                                  |
|--------------------------------------|-----------|------|--------------------------------------------|
| `proxy:bucket:{id}:count`           | String    | âˆ    | Contagem global de conexÃµes ativas         |
| `proxy:bucket:{id}:max`             | String    | âˆ    | Limite mÃ¡ximo de conexÃµes                  |
| `proxy:instance:{id}:conns`         | Hash      | âˆ    | `{ bucket_id: local_count }` por instÃ¢ncia |
| `proxy:instance:{id}:heartbeat`     | String    | 30s  | Timestamp, expira se instÃ¢ncia morrer      |
| `proxy:instances`                    | Set       | âˆ    | IDs de instÃ¢ncias ativas                   |
| `proxy:release:{bucket_id}` (canal) | Pub/Sub   | â€”    | NotificaÃ§Ã£o quando conexÃ£o Ã© liberada      |

### Scripts Lua (executados via EVALSHA)

**acquire.lua** â€” 3 KEYS: `count`, `max`, `instance_hash`
- `GET count` < `GET max` â†’ `INCR count` + `HINCRBY instance bucket 1`
- Retorna: `>0` (sucesso), `-1` (lotado), `-2` (max nÃ£o configurado)

**release.lua** â€” 2 KEYS: `count`, `instance_hash` + ARGV: `bucket_id`, `channel`
- ProteÃ§Ã£o contra underflow (count â‰¤ 0 â†’ SET 0)
- `DECR count` + `HINCRBY instance bucket -1` + `PUBLISH channel bucket_id`
- Retorna: novo count

---

## 8. Infraestrutura Docker

| Container          | Imagem                         | Portas (host)     | DescriÃ§Ã£o                 |
|--------------------|--------------------------------|-------------------|---------------------------|
| sqlserver-bucket-1 | mcr.microsoft.com/mssql/server | 14331:1433        | SQL Server bucket-001     |
| sqlserver-bucket-2 | mcr.microsoft.com/mssql/server | 14332:1433        | SQL Server bucket-002     |
| sqlserver-bucket-3 | mcr.microsoft.com/mssql/server | 14333:1433        | SQL Server bucket-003     |
| redis              | redis:7-alpine                 | 6379:6379         | CoordenaÃ§Ã£o distribuÃ­da   |
| proxy-1            | Dockerfile (Go multi-stage)    | 11433:1433, 18081:8080, 19091:9090 | Proxy instÃ¢ncia 1 |
| proxy-2            | Dockerfile                     | 11434:1433, 18082:8080, 19092:9090 | Proxy instÃ¢ncia 2 |
| proxy-3            | Dockerfile                     | 11435:1433, 18083:8080, 19093:9090 | Proxy instÃ¢ncia 3 |
| haproxy            | haproxy:3.1                    | 1433:1433, 8404:8404 | L4 TCP leastconn       |
| prometheus         | prom/prometheus                | 9090:9090         | Coleta mÃ©tricas           |
| grafana            | grafana/grafana-oss            | 3000:3000         | Dashboards                |
| init-db            | mcr.microsoft.com/mssql-tools  | â€”                 | Seed databases (run-once) |

**Rede:** `proxy-network` (bridge), todos os containers na mesma rede.

---

## 9. MÃ©tricas Prometheus

| MÃ©trica                           | Tipo      | Labels                        |
|-----------------------------------|-----------|-------------------------------|
| `proxy_connections_active`        | Gauge     | `bucket_id`                   |
| `proxy_connections_idle`          | Gauge     | `bucket_id`                   |
| `proxy_connections_pinned`        | Gauge     | `bucket_id`, `pin_reason`     |
| `proxy_connections_max`           | Gauge     | `bucket_id`                   |
| `proxy_connections_total`         | Counter   | `bucket_id`, `status`         |
| `proxy_queue_length`              | Gauge     | `bucket_id`                   |
| `proxy_queue_wait_seconds`        | Histogram | `bucket_id`                   |
| `proxy_tds_packets_total`         | Counter   | `bucket_id`, `direction`, `type` |
| `proxy_query_duration_seconds`    | Histogram | `bucket_id`                   |
| `proxy_connection_errors_total`   | Counter   | `bucket_id`, `error_type`     |
| `proxy_redis_operations_total`    | Counter   | `operation`, `status`         |
| `proxy_instance_heartbeat`        | Gauge     | `instance_id`                 |
| `proxy_pinning_duration_seconds`  | Histogram | `bucket_id`, `pin_reason`     |

---

## 10. ConfiguraÃ§Ã£o

### proxy.yaml (valores default)
```yaml
proxy:
  listen_addr: "0.0.0.0"    listen_port: 1433
  session_timeout: 5m        idle_timeout: 60s
  queue_timeout: 30s         pinning_mode: "transaction"
  health_check_port: 8080    metrics_port: 9090

redis:
  addr: "redis:6379"         pool_size: 20
  heartbeat_interval: 10s    heartbeat_ttl: 30s

fallback:
  enabled: true              local_limit_divisor: 3   # 50/3 â‰ˆ 16 conn/instance
```

### buckets.yaml (3 buckets idÃªnticos)
```yaml
buckets:
  - id: bucket-001/002/003   host: sqlserver-bucket-1/2/3
    port: 1433               database: tenant_db
    max_connections: 50       min_idle: 5
    max_idle_time: 300s       connection_timeout: 30s
```

---

## 11. Status das Fases

| Fase | Nome                            | Status | Notas                                                  |
|------|---------------------------------|--------|--------------------------------------------------------|
| 0    | Infraestrutura Docker           | âœ…     | 11 containers, tudo funcional                          |
| 1    | Pool Manager Local              | âœ…     | BucketPool com LIFO, wait queue, min_idle, eviction    |
| 2    | TDS Wire Protocol Proxy         | âœ…     | Relay TCP transparente apÃ³s Pre-Login                  |
| 3    | CoordenaÃ§Ã£o DistribuÃ­da (Redis) | âœ…     | Lua scripts, heartbeat, semÃ¡foro, fallback mode        |
| 4    | Session Pinning                 | ğŸ”²     | DetecÃ§Ã£o implementada, integraÃ§Ã£o pendente             |
| 5    | MÃ©tricas e Observabilidade      | ğŸ”²     | MÃ©tricas registradas, dashboards a completar           |
| 6    | Testes de Carga                 | ğŸ”²     |                                                        |
| 7    | DocumentaÃ§Ã£o Final              | ğŸ”²     |                                                        |

### Pontos de atenÃ§Ã£o para a prÃ³xima fase (4)
1. **O proxy NÃƒO faz parsing TDS apÃ³s Pre-Login** â€” usa `io.Copy` transparente
   - Para habilitar pinning, precisa trocar `io.Copy` por `tds.Relay` (apenas em modo sem TLS)
   - Ou implementar TLS termination no proxy para poder inspecionar pacotes
2. **O pool `*sql.DB` NÃƒO Ã© usado para trÃ¡fego TDS** â€” conexÃµes sÃ£o `net.Conn` diretas
   - O pool serve para health checks internos e `sp_reset_connection`
3. **O Router por Login7 estÃ¡ implementado mas nÃ£o ativado** â€” bucket Ã© escolhido via `pickBucket()` (primeiro bucket)
4. `pinning.go` tem implementaÃ§Ã£o completa (InspectPacket, InspectResponse, ENVCHANGE parsing) â€” falta integraÃ§Ã£o

---

## 12. Comandos Ãšteis

```bash
# Build
go build ./...
go vet ./...

# Deploy
docker compose -f deployments/docker-compose.yml up -d --build proxy-1 proxy-2 proxy-3

# Teste rÃ¡pido
docker exec sqlserver-bucket-1 /opt/mssql-tools18/bin/sqlcmd \
  -S host.docker.internal,1433 -U sa -P 'YourStr0ngP@ssword1' -C \
  -Q "SELECT @@SERVERNAME, GETDATE()"

# Redis
docker exec redis redis-cli SMEMBERS proxy:instances
docker exec redis redis-cli GET proxy:bucket:bucket-001:count
docker exec redis redis-cli HGETALL proxy:instance:<id>:conns

# MÃ©tricas
curl -s http://localhost:19091/metrics | grep proxy_redis

# Logs
docker logs proxy-1 2>&1 | grep coordinator
```
